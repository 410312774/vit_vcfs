{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7VXgfyGUQrUg",
   "metadata": {
    "id": "7VXgfyGUQrUg"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tRGmNSrlQjNf",
   "metadata": {
    "id": "tRGmNSrlQjNf"
   },
   "source": [
    "**Start the colab kernel with GPU**: Runtime -> Change runtime type -> GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Mw98qon1Qu7n",
   "metadata": {
    "id": "Mw98qon1Qu7n"
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MVBegNKTQXl9",
   "metadata": {
    "id": "MVBegNKTQXl9"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/suinleelab/vit-shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VfTqleJWQymH",
   "metadata": {
    "id": "VfTqleJWQymH"
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y torchtext torchaudio tensorflow arviz cxvpy\n",
    "!pip install -r vit-shapley/requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jEKb3RZzhsFN",
   "metadata": {
    "id": "jEKb3RZzhsFN"
   },
   "source": [
    "# Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "IQgS1darRIby",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1680483805576,
     "user": {
      "displayName": "Chanwoo Kim",
      "userId": "08649922516383873509"
     },
     "user_tz": 420
    },
    "id": "IQgS1darRIby"
   },
   "outputs": [],
   "source": [
    "# Add github repo to the python path.\n",
    "import sys\n",
    "sys.path.append(\"./vit-shapley\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6mO2ugnhkFH3",
   "metadata": {
    "executionInfo": {
     "elapsed": 5318,
     "status": "ok",
     "timestamp": 1680483810891,
     "user": {
      "displayName": "Chanwoo Kim",
      "userId": "08649922516383873509"
     },
     "user_tz": 420
    },
    "id": "6mO2ugnhkFH3"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from vit_shapley.config import config, dataset_ImageNette, dataset_MURA, dataset_Pet\n",
    "from vit_shapley.datamodules.ImageNette_datamodule import ImageNetteDataModule\n",
    "from vit_shapley.datamodules.MURA_datamodule import MURADataModule\n",
    "from vit_shapley.datamodules.Pet_datamodule import PetDataModule\n",
    "from vit_shapley.modules.explainer import Explainer\n",
    "from vit_shapley.modules.surrogate import Surrogate\n",
    "\n",
    "\n",
    "def download_file(url, path):\n",
    "  # Streaming, so we can iterate over the response.\n",
    "  response = requests.get(url, stream=True)\n",
    "  total_size_in_bytes= int(response.headers.get('content-length', 0))\n",
    "  block_size = 1024 #1 Kibibyte\n",
    "  progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "  with open(path, 'wb') as file:\n",
    "      for data in response.iter_content(block_size):\n",
    "          progress_bar.update(len(data))\n",
    "          file.write(data)\n",
    "  progress_bar.close()\n",
    "  if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "      print(\"ERROR, something went wrong\") \n",
    "\n",
    "def get_backbone_config(dataset_name):\n",
    "  if dataset_name == \"ImageNette\":\n",
    "      backbone_type_config_dict_ = OrderedDict(\n",
    "          {\n",
    "              \"vit_base_patch16_224\": {\n",
    "                  \"surrogate_path\": \"https://aimslab.cs.washington.edu/vitshapley/checkpoints/ImageNette_vit_base_patch16_224_surrogate_3i6zzjnp_state_dict.ckpt\",\n",
    "                  \"explainer_path\": \"https://aimslab.cs.washington.edu/vitshapley/checkpoints/ImageNette_vit_base_patch16_224_explainer_3ty85eft_state_dict.ckpt\",\n",
    "              },\n",
    "          }\n",
    "      )\n",
    "  elif dataset_name == \"MURA\":\n",
    "      backbone_type_config_dict_ = OrderedDict(\n",
    "          {\n",
    "              \"vit_base_patch16_224\": {\n",
    "                  \"surrogate_path\": \"https://aimslab.cs.washington.edu/vitshapley/checkpoints/MURA_vit_base_patch16_224_surrogate_22ompjqu_state_dict.ckpt\",\n",
    "                  \"explainer_path\": \"https://aimslab.cs.washington.edu/vitshapley/checkpoints/MURA_vit_base_patch16_224_explainer_1dmhcwej_state_dict.ckpt\",\n",
    "              },\n",
    "          }\n",
    "      )\n",
    "\n",
    "  elif dataset_name == \"Pet\":\n",
    "      backbone_type_config_dict_ = OrderedDict(\n",
    "          {\n",
    "              \"vit_base_patch16_224\": {\n",
    "                  \"surrogate_path\": \"https://aimslab.cs.washington.edu/vitshapley/checkpoints/Pet_vit_base_patch16_224_surrogate_146vf465_state_dict.ckpt\",\n",
    "                  \"explainer_path\": \"https://aimslab.cs.washington.edu/vitshapley/checkpoints/Pet_vit_base_patch16_224_explainer_2oq7lhr7_state_dict.ckpt\",\n",
    "              },\n",
    "          }\n",
    "      )    \n",
    "  return backbone_type_config_dict_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2yErFuQ4kiL_",
   "metadata": {
    "id": "2yErFuQ4kiL_"
   },
   "source": [
    "## Specifiy dataset name and backbone type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "LuLfOOAwRyD_",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1680484037915,
     "user": {
      "displayName": "Chanwoo Kim",
      "userId": "08649922516383873509"
     },
     "user_tz": 420
    },
    "id": "LuLfOOAwRyD_"
   },
   "outputs": [],
   "source": [
    "# In this example, we play with the Oxford IIIT-Pets dataset.\n",
    "\n",
    "dataset_name=\"Pet\"\n",
    "backbone_to_use=\"vit_base_patch16_224\"\n",
    "\n",
    "_config=config()\n",
    "if dataset_name==\"ImageNette\":\n",
    "  _config.update(dataset_ImageNette())\n",
    "elif dataset_name==\"MURA\":\n",
    "  _config.update(dataset_MURA())\n",
    "elif dataset_name==\"Pet\":\n",
    "  _config.update(dataset_Pet())    \n",
    "\n",
    "_config.update({'gpus_surrogate':[0,],\n",
    "                'gpus_explainer':[0,]})\n",
    "\n",
    "backbone_type_config = get_backbone_config(dataset_name)[backbone_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5pU4jkeOjqRS",
   "metadata": {
    "id": "5pU4jkeOjqRS"
   },
   "source": [
    "## Set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yl61to26c6rt",
   "metadata": {
    "id": "yl61to26c6rt"
   },
   "outputs": [],
   "source": [
    "dataset_parameters = {\n",
    "    \"dataset_location\": _config[\"dataset_location\"],\n",
    "    \"explanation_location_train\": _config[\"explanation_location_train\"],\n",
    "    \"explanation_mask_amount_train\": _config[\"explanation_mask_amount_train\"],\n",
    "    \"explanation_mask_ascending_train\": _config[\"explanation_mask_ascending_train\"],\n",
    "    \"explanation_location_val\": _config[\"explanation_location_val\"],\n",
    "    \"explanation_mask_amount_val\": _config[\"explanation_mask_amount_val\"],\n",
    "    \"explanation_mask_ascending_val\": _config[\"explanation_mask_ascending_val\"],\n",
    "    \"explanation_location_test\": _config[\"explanation_location_test\"],\n",
    "    \"explanation_mask_amount_test\": _config[\"explanation_mask_amount_test\"],\n",
    "    \"explanation_mask_ascending_test\": _config[\"explanation_mask_ascending_test\"],\n",
    "    \"transforms_train\": _config[\"transforms_train\"],\n",
    "    \"transforms_val\": _config[\"transforms_val\"],\n",
    "    \"transforms_test\": _config[\"transforms_test\"],\n",
    "    \"num_workers\": _config[\"num_workers\"],\n",
    "    \"per_gpu_batch_size\": _config[\"per_gpu_batch_size\"],\n",
    "    \"test_data_split\": _config[\"test_data_split\"],\n",
    "}\n",
    "\n",
    "if _config[\"datasets\"] == \"MURA\":\n",
    "    datamodule = MURADataModule(**dataset_parameters)\n",
    "elif _config[\"datasets\"] == \"ImageNette\":\n",
    "    datamodule = ImageNetteDataModule(**dataset_parameters)\n",
    "elif _config[\"datasets\"] == \"Pet\":\n",
    "    !mkdir pets\n",
    "    download_file(\n",
    "        \"https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz\",\n",
    "        \"pets_images.tar.gz\",\n",
    "    )\n",
    "    download_file(\n",
    "        \"https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz\",\n",
    "        \"pets_annotations.tar.gz\",\n",
    "    )\n",
    "    !tar -xvf pets_images.tar.gz -C ./pets\n",
    "    !tar -xvf pets_annotations.tar.gz -C ./pets\n",
    "    dataset_parameters[\"dataset_location\"] = \"./pets\"\n",
    "    datamodule = PetDataModule(**dataset_parameters)\n",
    "else:\n",
    "    ValueError(\"Invalid 'datasets' configuration\")\n",
    "\n",
    "datamodule.set_test_dataset()\n",
    "\n",
    "test_dataset = datamodule.test_dataset\n",
    "\n",
    "dset = test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Gdkf4zQNlbBX",
   "metadata": {
    "id": "Gdkf4zQNlbBX"
   },
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fWYi51ptpyY4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78340,
     "status": "ok",
     "timestamp": 1680484244100,
     "user": {
      "displayName": "Chanwoo Kim",
      "userId": "08649922516383873509"
     },
     "user_tz": 420
    },
    "id": "fWYi51ptpyY4",
    "outputId": "14ad6729-85ac-4472-a733-b27970b7baaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.37G/1.37G [01:15<00:00, 18.2MiB/s]\n"
     ]
    }
   ],
   "source": [
    "download_file(backbone_type_config[\"surrogate_path\"], \"surrogate.ckpt\")\n",
    "surrogate = Surrogate(mask_location=\"pre-softmax\",\n",
    "                      backbone_type=backbone_to_use,\n",
    "                      download_weight=False,\n",
    "                      load_path=\"surrogate.ckpt\",\n",
    "                      target_type=_config[\"target_type\"],\n",
    "                      output_dim=_config[\"output_dim\"],\n",
    "\n",
    "                      target_model=None,\n",
    "                      checkpoint_metric=None,\n",
    "                      optim_type=None,\n",
    "                      learning_rate=None,\n",
    "                      weight_decay=None,\n",
    "                      decay_power=None,\n",
    "                      warmup_steps=None,\n",
    "                      load_path_state_dict=True).to(_config[\"gpus_surrogate\"][0])\n",
    "                      \n",
    "download_file(backbone_type_config[\"explainer_path\"], \"explainer.ckpt\")\n",
    "explainer = Explainer(normalization=\"additive\",\n",
    "                      normalization_class=_config[\"explainer_normalization_class\"],\n",
    "                      activation=\"tanh\",\n",
    "                      surrogate=surrogate,\n",
    "                      link='sigmoid' if _config[\"output_dim\"]==1 else 'softmax',\n",
    "                      backbone_type=backbone_to_use,\n",
    "                      download_weight=False,\n",
    "                      residual=[],\n",
    "                      load_path=\"explainer.ckpt\",\n",
    "                      target_type=_config[\"target_type\"],\n",
    "                      output_dim=_config[\"output_dim\"],\n",
    "\n",
    "                      explainer_head_num_attention_blocks=1,\n",
    "                      explainer_head_include_cls=True,\n",
    "                      explainer_head_num_mlp_layers=3,\n",
    "                      explainer_head_mlp_layer_ratio=4,\n",
    "                      explainer_norm=_config[\"explainer_norm\"],\n",
    "\n",
    "                      efficiency_lambda=_config[\"explainer_efficiency_lambda\"],\n",
    "                      efficiency_class_lambda=_config[\"explainer_efficiency_class_lambda\"],\n",
    "                      freeze_backbone=\"all\",\n",
    "\n",
    "                      checkpoint_metric=_config[\"checkpoint_metric\"],\n",
    "                      optim_type=_config[\"optim_type\"],\n",
    "                      learning_rate=_config[\"learning_rate\"],\n",
    "                      weight_decay=_config[\"weight_decay\"],\n",
    "                      decay_power=_config[\"decay_power\"],\n",
    "                      warmup_steps=_config[\"warmup_steps\"],\n",
    "                      load_path_state_dict=True).to(_config[\"gpus_explainer\"][0])                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75H46vw7tY99",
   "metadata": {
    "id": "75H46vw7tY99"
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0tozGzBBkwFd",
   "metadata": {
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1680485037733,
     "user": {
      "displayName": "Chanwoo Kim",
      "userId": "08649922516383873509"
     },
     "user_tz": 420
    },
    "id": "0tozGzBBkwFd"
   },
   "outputs": [],
   "source": [
    "label_dict={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "EWfyn9qoq_Rw",
   "metadata": {
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1680485038735,
     "user": {
      "displayName": "Chanwoo Kim",
      "userId": "08649922516383873509"
     },
     "user_tz": 420
    },
    "id": "EWfyn9qoq_Rw"
   },
   "outputs": [],
   "source": [
    "def plot_figure(sample_idx_list, explainer):\n",
    "    plt.rcParams[\"font.size\"] = 8\n",
    "    img_mean = np.array([0.4914, 0.4822, 0.4465])[:, np.newaxis, np.newaxis]\n",
    "    img_std = np.array([0.2023, 0.1994, 0.2010])[:, np.newaxis, np.newaxis] \n",
    "\n",
    "    label_choice=[dset[sample_idx][\"labels\"] for sample_idx in sample_idx_list]\n",
    "    class_list = label_choice \n",
    "\n",
    "    fig = plt.figure(figsize=(1.53*(len([\"image\"]+class_list)+0.2*len([\"empty\"])), 2*len(sample_idx_list)))\n",
    "    box1 = gridspec.GridSpec(1, len([\"image\"]+[\"empty\"]+class_list), \n",
    "                              wspace=0.06, \n",
    "                              hspace=0,\n",
    "                              width_ratios=[1]+[0.2]+[1]*len(class_list))\n",
    "\n",
    "    axd={}\n",
    "    for idx1, plot_type in enumerate([\"image\"]+[\"empty\"]+class_list):\n",
    "        box2 = gridspec.GridSpecFromSubplotSpec(len(sample_idx_list),1, \n",
    "                                                subplot_spec=box1[idx1], wspace=0, hspace=0.2)\n",
    "        for idx2, sample_idx in enumerate(sample_idx_list):\n",
    "            box3 = gridspec.GridSpecFromSubplotSpec(1, 1,\n",
    "                                                subplot_spec=box2[idx2], wspace=0, hspace=0)\n",
    "            ax=plt.Subplot(fig, box3[0])\n",
    "            fig.add_subplot(ax)\n",
    "            axd[f\"{sample_idx}_{plot_type}\"]=ax\n",
    "\n",
    "    for plot_key in axd.keys():\n",
    "        if 'empty' in plot_key:\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(0) \n",
    "\n",
    "    for idx1, sample_idx in enumerate(sample_idx_list):\n",
    "        dataset_item=dset[sample_idx]\n",
    "\n",
    "        image = dataset_item[\"images\"]\n",
    "        label = dataset_item[\"labels\"]\n",
    "        path = dataset_item[\"path\"]\n",
    "\n",
    "        image_unnormlized=((image.numpy() * img_std) + img_mean).transpose(1,2,0)\n",
    "        assert image_unnormlized.min()>0 and image_unnormlized.max()<1\n",
    "        image_unnormlized_scaled=(image_unnormlized-image_unnormlized.min())/(image_unnormlized.max()-image_unnormlized.min())\n",
    "  \n",
    "        for idx2, plot_type in enumerate([\"image\"]+[\"empty\"]+class_list):\n",
    "            if plot_type==\"image\":\n",
    "                plot_key=f\"{sample_idx}_image\"\n",
    "                axd[plot_key].imshow(image_unnormlized_scaled)\n",
    "                if dataset_name==\"ImageNette\" or \"Pet\":\n",
    "                    axd[plot_key].set_title(f\"{label_dict[dataset_name][label_choice[idx1]]}\", pad=7, zorder=10)\n",
    "                else:\n",
    "                    axd[plot_key].set_title(f\"Abnormal\", pad=7, zorder=10)\n",
    "            elif plot_type==\"empty\":\n",
    "                pass\n",
    "            else:         \n",
    "                plot_key=f\"{sample_idx}_{plot_type}\"\n",
    "                explanation=explainer(image.unsqueeze(0).to(explainer.device))[0][0].T\n",
    "                if len(explanation.shape)==2:\n",
    "                    explanation_class=explanation[plot_type].detach().cpu().numpy()\n",
    "                else:\n",
    "                    explanation_class=explanation.detach().cpu().numpy()\n",
    "\n",
    "                explanation_class_expanded=np.repeat(np.repeat(explanation_class.reshape(14, 14), 16, axis=0), 16, axis=1)\n",
    "                explanation_class_expanded=torch.nn.functional.interpolate(torch.Tensor(explanation_class.reshape(1, 1, 14, 14)), \n",
    "                                                                          scale_factor=16, align_corners=False, mode='bilinear').numpy().reshape(224, 224)                                                        \n",
    "\n",
    "                explanation_class_expanded_normalized=(0.5+(explanation_class_expanded)/np.max(np.abs(explanation_class_expanded))*0.5)\n",
    "                explanation_class_expanded_heatmap=sns.color_palette(\"icefire\", as_cmap=True)(explanation_class_expanded_normalized)#[:,:,:-1]\n",
    "                explanation_class_expanded_heatmap[:,:,3]=0.6\n",
    "\n",
    "                image_unnormlized_normalized=(image_unnormlized.sum(axis=2))/3\n",
    "                image_unnormlized_normalized=cm.get_cmap('Greys', 1000)(1-image_unnormlized_normalized)#[:,:,:-1]\n",
    "                image_unnormlized_normalized[:,:,3]=0.5\n",
    "\n",
    "                axd[plot_key].imshow(image_unnormlized_normalized, alpha=0.85)\n",
    "                axd[plot_key].imshow(explanation_class_expanded_heatmap, alpha=0.9)\n",
    "\n",
    "                axd[plot_key].set_title(label_dict[dataset_name][plot_type])\n",
    "\n",
    "            axd[plot_key].set_xticks([])\n",
    "            axd[plot_key].set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                axd[plot_key].spines[axis].set_linewidth(1)  \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EZ71iiyLu6ZF",
   "metadata": {
    "id": "EZ71iiyLu6ZF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/suinleelab/vit-shapley/blob/master/notebooks/example.ipynb",
     "timestamp": 1680393535347
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
